{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install torch-geometric\n",
        "!pip install torch-scatter\n",
        "!pip install torch-cluster"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pEhK1fRWzeWv",
        "outputId": "5fc75bb4-3f79-4b63-954e-c47f25ad9fbb"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch-geometric in /usr/local/lib/python3.11/dist-packages (2.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.11.15)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2025.3.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.2.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (4.67.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (6.3.2)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.18.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch-geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2025.1.31)\n",
            "Requirement already satisfied: torch-scatter in /usr/local/lib/python3.11/dist-packages (2.1.2)\n",
            "Requirement already satisfied: torch-cluster in /usr/local/lib/python3.11/dist-packages (1.6.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from torch-cluster) (1.14.1)\n",
            "Requirement already satisfied: numpy<2.3,>=1.23.5 in /usr/local/lib/python3.11/dist-packages (from scipy->torch-cluster) (2.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "from typing import List, Tuple, Optional\n",
        "\n",
        "import torch\n",
        "from torch import Tensor\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import MessagePassing\n",
        "from torch_geometric.utils import degree\n",
        "from torch_scatter import scatter\n",
        "from torch_cluster import random_walk\n"
      ],
      "metadata": {
        "id": "9Nz3I4DnzenR"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from torch_geometric.utils import to_undirected\n",
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "metadata": {
        "id": "jKLA5T7ZELcQ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://files.grouplens.org/datasets/movielens/ml-100k.zip\n",
        "!unzip -q ml-100k.zip\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aIvSyzRfEkly",
        "outputId": "62433930-7783-41d8-8628-5e813dda91b2"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-04-13 20:06:10--  http://files.grouplens.org/datasets/movielens/ml-100k.zip\n",
            "Resolving files.grouplens.org (files.grouplens.org)... 128.101.65.152\n",
            "Connecting to files.grouplens.org (files.grouplens.org)|128.101.65.152|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4924029 (4.7M) [application/zip]\n",
            "Saving to: ‘ml-100k.zip.2’\n",
            "\n",
            "ml-100k.zip.2       100%[===================>]   4.70M  12.0MB/s    in 0.4s    \n",
            "\n",
            "2025-04-13 20:06:10 (12.0 MB/s) - ‘ml-100k.zip.2’ saved [4924029/4924029]\n",
            "\n",
            "replace ml-100k/allbut.pl? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "replace ml-100k/mku.sh? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "replace ml-100k/README? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "replace ml-100k/u.data? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "replace ml-100k/u.genre? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "replace ml-100k/u.info? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "replace ml-100k/u.item? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "replace ml-100k/u.occupation? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "replace ml-100k/u.user? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "replace ml-100k/u1.base? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "replace ml-100k/u1.test? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "replace ml-100k/u2.base? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "replace ml-100k/u2.test? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "replace ml-100k/u3.base? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "replace ml-100k/u3.test? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "replace ml-100k/u4.base? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "replace ml-100k/u4.test? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "replace ml-100k/u5.base? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "replace ml-100k/u5.test? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "replace ml-100k/ua.base? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "replace ml-100k/ua.test? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "replace ml-100k/ub.base? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "replace ml-100k/ub.test? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fqa-tnyGsqlv",
        "outputId": "d55dcb9a-c25d-4fca-90eb-fa8b8c9e85a6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from torch_geometric.data import HeteroData\n",
        "from torch_geometric.utils import to_undirected\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "def load_movielens_100k(path='ml-100k/u.data', user_path='ml-100k/u.user', item_path='ml-100k/u.item'):\n",
        "    import pandas as pd\n",
        "    from sklearn.preprocessing import LabelEncoder\n",
        "    import torch\n",
        "    from torch_geometric.data import HeteroData\n",
        "\n",
        "    # ---- Load user features ----\n",
        "    user_cols = ['user_id', 'age', 'gender', 'occupation', 'zip']\n",
        "    user_df = pd.read_csv(user_path, sep='|', names=user_cols, encoding='latin-1')\n",
        "    # Convert categorical features if needed (e.g., gender)\n",
        "    le = LabelEncoder()\n",
        "    user_df['gender'] = le.fit_transform(user_df['gender'])\n",
        "    # For example, use age and gender as features\n",
        "    user_features = user_df[['age', 'gender']]\n",
        "    x_user = torch.tensor(user_features.values, dtype=torch.float)\n",
        "\n",
        "    # ---- Load item features ----\n",
        "    item_cols = ['item_id', 'title', 'release_date', 'video_release_date', 'IMDb_URL',\n",
        "                 'unknown', 'Action', 'Adventure', 'Animation', 'Children', 'Comedy',\n",
        "                 'Crime', 'Documentary', 'Drama', 'Fantasy', 'Film-Noir', 'Horror', 'Musical',\n",
        "                 'Mystery', 'Romance', 'Sci-Fi', 'Thriller', 'War', 'Western']\n",
        "    item_df = pd.read_csv(item_path, sep='|', names=item_cols, encoding='latin-1')\n",
        "    genre_cols = item_cols[5:]  # use genre flags as features\n",
        "    x_item = torch.tensor(item_df[genre_cols].values, dtype=torch.float)\n",
        "\n",
        "    # ---- Create edge_index from ratings ----\n",
        "    ratings_df = pd.read_csv(path, sep='\\t', names=['user', 'item', 'rating', 'timestamp'])\n",
        "    # Subtract 1 to convert from 1-indexed to 0-indexed\n",
        "    user_tensor = torch.tensor(ratings_df['user'].values, dtype=torch.long) - 1\n",
        "    item_tensor = torch.tensor(ratings_df['item'].values, dtype=torch.long) - 1 + x_user.size(0)\n",
        "    edge_index = torch.stack([user_tensor, item_tensor], dim=0)\n",
        "\n",
        "    # Number of users and items\n",
        "    num_users = x_user.size(0)\n",
        "    num_items = x_item.size(0)\n",
        "\n",
        "    # ---------- make feature dims equal ----------\n",
        "    feat_dim = max(x_user.size(1), x_item.size(1))\n",
        "    if x_user.size(1) < feat_dim:\n",
        "        x_user = torch.nn.functional.pad(x_user, (0, feat_dim - x_user.size(1)), \"constant\", 0)\n",
        "    if x_item.size(1) < feat_dim:\n",
        "        x_item = torch.nn.functional.pad(x_item, (0, feat_dim - x_item.size(1)), \"constant\", 0)\n",
        "\n",
        "    # Create the HeteroData object\n",
        "    data = HeteroData()\n",
        "    data[\"user\"].x = x_user\n",
        "    data[\"item\"].x = x_item\n",
        "    data[\"user\", \"rates\", \"item\"].edge_index = edge_index\n",
        "\n",
        "    return data, num_users, num_items\n"
      ],
      "metadata": {
        "id": "sGnp04x7Fv7j"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "######################################################################\n",
        "# Utility: importance‑based neighbor sampling via random walks       #\n",
        "######################################################################\n",
        "\n",
        "def importance_sampling(\n",
        "    edge_index: Tensor,\n",
        "    num_nodes: int,\n",
        "    seed_nodes: Tensor,\n",
        "    walk_length: int = 2,\n",
        "    num_walks: int = 200,\n",
        "    top_k: int = 50,\n",
        "    device: Optional[torch.device] = None,\n",
        ") -> Tuple[Tensor, Tensor]:\n",
        "    \"\"\"Improved importance sampling with robust neighbor handling\"\"\"\n",
        "    device = device or seed_nodes.device\n",
        "\n",
        "    # Convert to undirected graph for better connectivity\n",
        "    undir_edge_index = to_undirected(edge_index)\n",
        "\n",
        "    # Launch random walks\n",
        "    start = seed_nodes.repeat_interleave(num_walks)\n",
        "    walks = random_walk(undir_edge_index[0], undir_edge_index[1], start, walk_length, num_nodes=num_nodes)\n",
        "\n",
        "    # Get first-step neighbors and remove invalid ones\n",
        "    nbrs = walks[:, 1]\n",
        "    valid_mask = nbrs != -1\n",
        "    nbrs = nbrs[valid_mask]\n",
        "\n",
        "    # Fallback 1: If no neighbors found at all, use direct neighbors from edge_index\n",
        "    if len(nbrs) == 0:\n",
        "        # Get direct neighbors from original edge_index\n",
        "        rows, cols = [], []\n",
        "        for i, seed in enumerate(seed_nodes):\n",
        "            mask = edge_index[0] == seed\n",
        "            neighbors = edge_index[1][mask]\n",
        "            if len(neighbors) > 0:\n",
        "                rows.append(torch.full_like(neighbors, i))\n",
        "                cols.append(neighbors)\n",
        "            else:\n",
        "                # Add self-loop if no neighbors found\n",
        "                rows.append(torch.tensor([i], device=device))\n",
        "                cols.append(torch.tensor([seed], device=device))\n",
        "\n",
        "        sub_edge_index = torch.stack([torch.cat(rows), torch.cat(cols)], dim=0)\n",
        "        edge_weight = torch.ones(sub_edge_index.size(1), device=device)\n",
        "        return sub_edge_index, edge_weight\n",
        "\n",
        "    # Count visit frequency\n",
        "    counts = scatter(torch.ones_like(nbrs, dtype=torch.float), nbrs, dim=0,\n",
        "                    dim_size=num_nodes, reduce='sum')\n",
        "    counts = counts / counts.sum().clamp(min=1e-6)\n",
        "\n",
        "    # Build neighbor lists with fallbacks\n",
        "    rows, cols, weights = [], [], []\n",
        "    for i, seed in enumerate(seed_nodes):\n",
        "        # Get all possible neighbors\n",
        "        mask = undir_edge_index[0] == seed\n",
        "        neighbors = undir_edge_index[1][mask]\n",
        "\n",
        "        # Fallback to direct neighbors if random walk found none\n",
        "        if len(neighbors) == 0:\n",
        "            mask = edge_index[0] == seed\n",
        "            neighbors = edge_index[1][mask]\n",
        "\n",
        "        # Final fallback to self-loop\n",
        "        if len(neighbors) == 0:\n",
        "            rows.append(torch.tensor([i], device=device))\n",
        "            cols.append(torch.tensor([seed], device=device))\n",
        "            weights.append(torch.tensor([1.0], device=device))\n",
        "            continue\n",
        "\n",
        "        # Get top-k neighbors by visit count\n",
        "        neighbor_scores = counts[neighbors]\n",
        "        if len(neighbors) > top_k:\n",
        "            neighbor_scores, idx = torch.topk(neighbor_scores, top_k)\n",
        "            neighbors = neighbors[idx]\n",
        "\n",
        "        rows.append(torch.full_like(neighbors, i))\n",
        "        cols.append(neighbors)\n",
        "        weights.append(neighbor_scores)\n",
        "\n",
        "    # Final assembly\n",
        "    sub_edge_index = torch.stack([torch.cat(rows), torch.cat(cols)], dim=0)\n",
        "    edge_weight = torch.cat(weights)\n",
        "\n",
        "    return sub_edge_index.to(device), edge_weight.to(device)"
      ],
      "metadata": {
        "id": "-uQQETICzf4C"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "######################################################################\n",
        "# PinSage convolution layer                                          #\n",
        "######################################################################\n",
        "\n",
        "class PinSageConv(MessagePassing):\n",
        "    \"\"\"PinSage convolution layer with importance (weighted mean) pooling.\n",
        "\n",
        "    Follows the formulation from Ying et al., KDD'18.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, in_channels: int, out_channels: int):\n",
        "        super().__init__(aggr='add')  # we will divide by weights later\n",
        "        self.lin_neighbor = torch.nn.Linear(in_channels, out_channels, bias=True)\n",
        "        self.lin_root = torch.nn.Linear(in_channels + out_channels, out_channels,\n",
        "                                        bias=True)\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        torch.nn.init.xavier_uniform_(self.lin_neighbor.weight)\n",
        "        torch.nn.init.zeros_(self.lin_neighbor.bias)\n",
        "        torch.nn.init.xavier_uniform_(self.lin_root.weight)\n",
        "        torch.nn.init.zeros_(self.lin_root.bias)\n",
        "\n",
        "    def forward(self, x: Tensor, edge_index: Tensor, edge_weight: Tensor):\n",
        "        \"\"\"Args:\n",
        "            x: Node features [N, F]. Assumes 0..B‑1 correspond to target nodes.\n",
        "            edge_index: [2, E] with edges from *target nodes* to their sampled\n",
        "                neighbors.\n",
        "            edge_weight: Importance weight per edge, must be positive.\n",
        "        Returns:\n",
        "            Updated representations for the first B (target) nodes.\n",
        "        \"\"\"\n",
        "        h = self.lin_neighbor(x)\n",
        "        # propagate returns weighted sum; we pass weights via 'norm'.\n",
        "        out = self.propagate(edge_index, x=h, norm=edge_weight)\n",
        "\n",
        "        # Compute denominator per destination (row in COO).\n",
        "        denom = scatter(edge_weight, edge_index[0], dim=0, dim_size=out.size(0),\n",
        "                        reduce='sum').clamp(min=1e-6).unsqueeze(-1)\n",
        "        out = out / denom  # weighted mean\n",
        "\n",
        "        # concatenate with root features\n",
        "        root = x[:out.size(0)]  # first B nodes are roots\n",
        "        out = torch.cat([root, out], dim=-1)\n",
        "        out = F.relu(self.lin_root(out))\n",
        "        return F.normalize(out, p=2.0, dim=-1)\n",
        "\n",
        "    def message(self, x_j: Tensor, norm: Tensor) -> Tensor:  # noqa: N802\n",
        "        return norm.view(-1, 1) * x_j\n"
      ],
      "metadata": {
        "id": "R8fV2rd46V8S"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "######################################################################\n",
        "# PinSage model                                                      #\n",
        "######################################################################\n",
        "\n",
        "class PinSageModel(torch.nn.Module):\n",
        "    \"\"\"Two‑layer PinSage network (easily extendable).\"\"\"\n",
        "\n",
        "    def __init__(self, in_channels: int, hidden_channels: int, num_layers: int = 2):\n",
        "        super().__init__()\n",
        "        self.convs = torch.nn.ModuleList()\n",
        "        for i in range(num_layers):\n",
        "            in_ch = in_channels if i == 0 else hidden_channels\n",
        "            self.convs.append(PinSageConv(in_ch, hidden_channels))\n",
        "        # final projection as in paper\n",
        "        self.project = torch.nn.Linear(hidden_channels, hidden_channels)\n",
        "        self.num_layers = num_layers\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        for conv in self.convs:\n",
        "            conv.reset_parameters()\n",
        "        torch.nn.init.xavier_uniform_(self.project.weight)\n",
        "        torch.nn.init.zeros_(self.project.bias)\n",
        "\n",
        "    def forward(self, x: Tensor, edge_index: Tensor, edge_weight: Tensor,\n",
        "                batch_size: int) -> Tensor:\n",
        "        \"\"\"Computes embeddings for *batch_size* seed nodes.\n",
        "\n",
        "        x contains features for *batch_size + batch_size*top_k* nodes;\n",
        "        the first *batch_size* rows correspond to seeds.\n",
        "        \"\"\"\n",
        "        for conv in self.convs:\n",
        "            x = conv(x, edge_index, edge_weight)\n",
        "        z = F.relu(self.project(x[:batch_size]))  # only seed embeddings\n",
        "        return F.normalize(z, p=2.0, dim=-1)"
      ],
      "metadata": {
        "id": "951boo5azk4J"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "######################################################################\n",
        "# Mini‑batch training harness                                        #\n",
        "######################################################################\n",
        "\n",
        "class PinSageTrainer:\n",
        "    \"\"\"Utility class encapsulating training loop with max‑margin loss.\"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        model: PinSageModel,\n",
        "        edge_index: Tensor,\n",
        "        num_nodes: int,\n",
        "        device: torch.device,\n",
        "        walk_length: int = 2,\n",
        "        num_walks: int = 200,\n",
        "        top_k: int = 50,\n",
        "        margin: float = 0.1,\n",
        "    ):\n",
        "        self.model = model.to(device)\n",
        "        self.edge_index = edge_index.to(device)\n",
        "        self.num_nodes = num_nodes\n",
        "        self.device = device\n",
        "        self.walk_length = walk_length\n",
        "        self.num_walks = num_walks\n",
        "        self.top_k = top_k\n",
        "        self.margin = margin\n",
        "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=1e-3)\n",
        "\n",
        "    def batch(self, seeds: Tensor, x_full: Tensor) -> Tuple[Tensor, Tensor, Tensor, int]:\n",
        "        \"\"\"Prepares mini-batch graph and returns (x, edge_index, edge_weight, batch_size).\"\"\"\n",
        "        seeds = seeds.to(self.device)\n",
        "        batch_size = len(seeds)\n",
        "\n",
        "        # Sample neighbors\n",
        "        sub_edge_index, edge_weight = importance_sampling(\n",
        "            self.edge_index, self.num_nodes, seeds,\n",
        "            walk_length=self.walk_length, num_walks=self.num_walks,\n",
        "            top_k=self.top_k, device=self.device)\n",
        "\n",
        "        # Get all required nodes\n",
        "        all_nodes = torch.cat([seeds, sub_edge_index[1]]).unique()\n",
        "\n",
        "        # Map global node IDs to local IDs\n",
        "        node_map = {int(node): i for i, node in enumerate(all_nodes.tolist())}\n",
        "\n",
        "        # Remap edge indices to local IDs\n",
        "        row = torch.tensor([node_map[int(seeds[idx])] for idx in sub_edge_index[0].tolist()],\n",
        "                          device=self.device)\n",
        "        col = torch.tensor([node_map[int(idx)] for idx in sub_edge_index[1].tolist()],\n",
        "                          device=self.device)\n",
        "        sub_edge_index_local = torch.stack([row, col], dim=0)\n",
        "\n",
        "        # Get features for batch nodes\n",
        "        x_batch = x_full[all_nodes]\n",
        "\n",
        "        return x_batch, sub_edge_index_local, edge_weight, batch_size\n",
        "\n",
        "    def max_margin_loss(self, z_q: Tensor, z_pos: Tensor, z_neg: Tensor) -> Tensor:\n",
        "        pos_sim = (z_q * z_pos).sum(dim=-1)\n",
        "        neg_sim = (z_q.unsqueeze(1) * z_neg).sum(dim=-1)  # [B, Kneg]\n",
        "        loss = F.relu(neg_sim - pos_sim.unsqueeze(1) + self.margin).mean()\n",
        "        return loss\n",
        "\n",
        "    def bpr_loss(self, z_q: Tensor, z_pos: Tensor, z_neg: Tensor) -> Tensor:\n",
        "        # z_neg: [B, Kneg, d]\n",
        "        pos_sim = (z_q * z_pos).sum(dim=-1)                     # [B]\n",
        "        neg_sim = (z_q.unsqueeze(1) * z_neg).sum(dim=-1)        # [B, Kneg]\n",
        "        return -torch.log(torch.sigmoid(pos_sim.unsqueeze(1) - neg_sim)).mean()\n",
        "\n",
        "    def train_step(self, seeds: Tensor, pos: Tensor, neg: Tensor,\n",
        "               x_full: Tensor):\n",
        "        self.model.train()\n",
        "        seeds, pos, neg = [t.to(self.device) for t in (seeds, pos, neg)]\n",
        "\n",
        "        # ------- build mini‑batch sub‑graph -------\n",
        "        x_batch, sub_edge_index, edge_w, B = self.batch(\n",
        "            seeds, x_full\n",
        "        )\n",
        "\n",
        "        # ------- forward -------\n",
        "        z_all = self.model(x_batch, sub_edge_index, edge_w, B)  # [B, d]\n",
        "        z_q   = z_all                                           # queries\n",
        "        z_pos = self.model(x_full[pos],                         # reuse linear proj\n",
        "                          torch.empty(2,0, dtype=torch.long, device=self.device),\n",
        "                          torch.empty(0,  device=self.device),\n",
        "                          pos.size(0))\n",
        "        z_neg = self.model(x_full[neg.view(-1)]\n",
        "                          .view(neg.shape[0], neg.shape[1], -1)\n",
        "                          .reshape(-1, x_full.size(1)),\n",
        "                          torch.empty(2,0, dtype=torch.long, device=self.device),\n",
        "                          torch.empty(0,  device=self.device),\n",
        "                          neg.numel()).view(neg.shape[0], neg.shape[1], -1)\n",
        "\n",
        "        # inside train_step, just before backward()\n",
        "        loss = self.bpr_loss(z_q, z_pos, z_neg)\n",
        "\n",
        "\n",
        "        self.optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        self.optimizer.step()\n",
        "        return float(loss)\n"
      ],
      "metadata": {
        "id": "uLpOKE2v5zo3"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ── NEW: get_all_embeddings ─────────────────────────────────────\n",
        "@torch.no_grad()\n",
        "def get_all_embeddings(model, x_full, edge_index, batch_size=4096):\n",
        "    model.eval()\n",
        "    num_nodes = x_full.size(0)\n",
        "    z = torch.empty(num_nodes, model.project.out_features,\n",
        "                    device=x_full.device)\n",
        "    ptr = 0\n",
        "    while ptr < num_nodes:\n",
        "        batch_nodes = torch.arange(ptr, min(ptr+batch_size, num_nodes),\n",
        "                                   device=x_full.device)\n",
        "        # 1‑hop importance sampling (cheap) for inference\n",
        "        sub_ei, ew = importance_sampling(edge_index, num_nodes,\n",
        "                                         batch_nodes, top_k=50,\n",
        "                                         num_walks=50, device=x_full.device)\n",
        "        x_batch = x_full[torch.cat([batch_nodes, sub_ei[1]]).unique()]\n",
        "        # remap as in trainer.batch()\n",
        "        node_map = {int(n): i for i, n in enumerate(x_batch.unique().tolist())}\n",
        "        row = torch.tensor([node_map[int(n)] for n in sub_ei[0].tolist()],\n",
        "                           device=x_full.device)\n",
        "        col = torch.tensor([node_map[int(n)] for n in sub_ei[1].tolist()],\n",
        "                           device=x_full.device)\n",
        "        z_batch = model(x_batch,\n",
        "                        torch.stack([row, col], 0),\n",
        "                        ew, batch_nodes.size(0))\n",
        "        z[batch_nodes] = z_batch\n",
        "        ptr += batch_size\n",
        "    return F.normalize(z, dim=-1)\n"
      ],
      "metadata": {
        "id": "LRoZdlJF1Mfk"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data, num_users, num_items = load_movielens_100k()\n",
        "# x_full = torch.cat([data[\"user\"].x, data[\"item\"].x], dim=0).to(device)\n",
        "# edge_index = data[\"user\", \"rates\", \"item\"].edge_index.to(device)\n",
        "\n",
        "# evaluate_model(model, x_full, edge_index, num_users, num_items)\n"
      ],
      "metadata": {
        "id": "vbPhlfQwGDvx"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data, num_users, num_items = load_movielens_100k()\n",
        "data = data.to(device)\n",
        "num_nodes = num_users + num_items # Calculate num_nodes\n"
      ],
      "metadata": {
        "id": "ov3pUNO_WpjQ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Create the full feature matrix ---\n",
        "# Ensure features are created correctly (similar to the first train_model function)\n",
        "# Example: Assuming 'data' has user and item features loaded correctly\n",
        "x_user = data['user'].x\n",
        "x_item = data['item'].x\n",
        "# Pad features if necessary (as done in load_movielens_100k)\n",
        "feat_dim = max(x_user.size(1), x_item.size(1))\n",
        "if x_user.size(1) < feat_dim:\n",
        "    x_user = torch.nn.functional.pad(x_user, (0, feat_dim - x_user.size(1)), \"constant\", 0)\n",
        "if x_item.size(1) < feat_dim:\n",
        "    x_item = torch.nn.functional.pad(x_item, (0, feat_dim - x_item.size(1)), \"constant\", 0)\n",
        "\n",
        "x_full = torch.cat([x_user, x_item], dim=0).to(device)\n",
        "print(f\"Full feature matrix shape: {x_full.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CZk-PBkGu67D",
        "outputId": "271bcbfc-6775-4f96-ea38-6f5968439f00"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Full feature matrix shape: torch.Size([2625, 19])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.transforms import RandomLinkSplit"
      ],
      "metadata": {
        "id": "GCoxjMBwxhDg"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split edges into train/val/test\n",
        "transform = RandomLinkSplit(\n",
        "    num_val=0.1,\n",
        "    num_test=0.1,\n",
        "    is_undirected=False, # Important if graph is directed (user->item)\n",
        "    add_negative_train_samples=False, # Set to False if trainer handles neg sampling\n",
        "    # Neg_sampling_ratio is only relevant if add_negative_train_samples=True\n",
        "    edge_types=(\"user\", \"rates\", \"item\"),\n",
        "    rev_edge_types=None, # Adjust if you have reverse edges\n",
        ")\n",
        "# Ensure data is on the correct device before transform if needed\n",
        "train_data, val_data, test_data = transform(data)\n",
        "print(\"Data split completed.\")\n",
        "print(\"Train data:\", train_data)\n",
        "print(\"Validation data:\", val_data)\n",
        "print(\"Test data:\", test_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ixdk_bBzu94o",
        "outputId": "3f88777a-5823-4a4a-a888-3e13c5333ec2"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data split completed.\n",
            "Train data: HeteroData(\n",
            "  user={ x=[943, 19] },\n",
            "  item={ x=[1682, 19] },\n",
            "  (user, rates, item)={\n",
            "    edge_index=[2, 80000],\n",
            "    edge_label=[80000],\n",
            "    edge_label_index=[2, 80000],\n",
            "  }\n",
            ")\n",
            "Validation data: HeteroData(\n",
            "  user={ x=[943, 19] },\n",
            "  item={ x=[1682, 19] },\n",
            "  (user, rates, item)={\n",
            "    edge_index=[2, 80000],\n",
            "    edge_label=[20000],\n",
            "    edge_label_index=[2, 20000],\n",
            "  }\n",
            ")\n",
            "Test data: HeteroData(\n",
            "  user={ x=[943, 19] },\n",
            "  item={ x=[1682, 19] },\n",
            "  (user, rates, item)={\n",
            "    edge_index=[2, 90000],\n",
            "    edge_label=[20000],\n",
            "    edge_label_index=[2, 20000],\n",
            "  }\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train model on train_data\n",
        "# Make sure in_channels matches the feature dimension after padding\n",
        "model = PinSageModel(in_channels=x_full.size(1), hidden_channels=128).to(device)\n",
        "\n",
        "# Use the edge_index from train_data for the trainer\n",
        "trainer = PinSageTrainer(model, train_data[\"user\", \"rates\", \"item\"].edge_index,\n",
        "                         num_nodes, device) # Pass num_nodes\n"
      ],
      "metadata": {
        "id": "BmKJ8VYTvAnw"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Build interaction dictionary based *only* on training edges ---\n",
        "train_edge_index = train_data[\"user\", \"rates\", \"item\"].edge_index.cpu() # Move to CPU for iteration\n",
        "user_to_items_train = {}\n",
        "for i in range(train_edge_index.size(1)):\n",
        "    user = train_edge_index[0, i].item()\n",
        "    item = train_edge_index[1, i].item()\n",
        "    if user < num_users: # Ensure it's a user node\n",
        "        if user not in user_to_items_train:\n",
        "            user_to_items_train[user] = set() # Use set for faster lookups\n",
        "        user_to_items_train[user].add(item)\n",
        "\n",
        "print(f\"Built training interaction dictionary for {len(user_to_items_train)} users.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vVOw1xs8vDXP",
        "outputId": "da5519ca-7c76-4b38-de8c-9f03b7e6d626"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Built training interaction dictionary for 943 users.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import time\n",
        "\n",
        "from sklearn.metrics import recall_score\n",
        "\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "lvoXYxe5xj7O"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Corrected Training loop ---\n",
        "print(\"Starting training...\")\n",
        "start_time = time.time()\n",
        "for epoch in range(1, 21): # Example: 20 epochs\n",
        "    valid_users = list(user_to_items_train.keys())\n",
        "\n",
        "    if not valid_users:\n",
        "        print(\"No users with training interactions found. Stopping training.\")\n",
        "        break\n",
        "\n",
        "    # --- Batch Generation ---\n",
        "    batch_size = min(512, len(valid_users)) # Example batch size\n",
        "    user_indices = np.random.choice(valid_users, batch_size, replace=False)\n",
        "\n",
        "    seeds_list, pos_items_list, neg_items_list = [], [], []\n",
        "    items_set = set(range(num_users, num_nodes)) # All item indices (global)\n",
        "\n",
        "    for user_idx in user_indices:\n",
        "        pos_candidates = list(user_to_items_train[user_idx]) # Items user interacted with in train set\n",
        "\n",
        "        if not pos_candidates:\n",
        "            continue # Skip user if no positive items in training set\n",
        "\n",
        "        # Sample one positive item\n",
        "        pos_item = np.random.choice(pos_candidates)\n",
        "\n",
        "        # Sample negative items\n",
        "        user_train_items = user_to_items_train[user_idx]\n",
        "        neg_candidates = list(items_set - user_train_items) # Items user DID NOT interact with in train set\n",
        "\n",
        "        if len(neg_candidates) < 5: # Need at least 5 negatives\n",
        "             # print(f\"Warning: User {user_idx} has only {len(neg_candidates)} neg candidates. Skipping.\")\n",
        "             continue\n",
        "\n",
        "        neg_sample = np.random.choice(neg_candidates, 5, replace=False) # Sample 5 negatives\n",
        "\n",
        "        # Add to batch lists\n",
        "        seeds_list.append(user_idx)\n",
        "        pos_items_list.append(pos_item)\n",
        "        neg_items_list.append(neg_sample)\n",
        "\n",
        "    if not seeds_list:\n",
        "        print(f\"Epoch {epoch:02d} | No valid training pairs generated in this batch. Skipping epoch.\")\n",
        "        continue\n",
        "\n",
        "    # Convert lists to tensors\n",
        "    seeds = torch.tensor(seeds_list, dtype=torch.long)\n",
        "    pos = torch.tensor(pos_items_list, dtype=torch.long)\n",
        "    neg = torch.tensor(neg_items_list, dtype=torch.long)\n",
        "\n",
        "    # print(f\"Epoch {epoch:02d} | Batch shapes: Seeds: {seeds.shape}, Pos: {pos.shape}, Neg: {neg.shape}\")\n",
        "\n",
        "    # --- Call train_step with all arguments ---\n",
        "    try:\n",
        "        loss = trainer.train_step(seeds, pos, neg, x_full)\n",
        "        epoch_time = time.time() - start_time\n",
        "        print(f\"Epoch {epoch:02d} | Loss: {loss:.4f} | Time: {epoch_time:.2f}s | Batch Users: {len(seeds_list)}\")\n",
        "    except Exception as e:\n",
        "         print(f\"Error during training step in epoch {epoch}: {e}\")\n",
        "         # Optionally add more detailed error logging or debugging here\n",
        "         # import traceback\n",
        "         # traceback.print_exc()\n",
        "         continue # Continue to next epoch or break if needed\n",
        "\n",
        "print(\"Training finished.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZjaecSn7vFWZ",
        "outputId": "fbcc59c9-3a85-4245-93ed-ac5915a762a6"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-22-69fe366b3b0a>:49: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:254.)\n",
            "  neg = torch.tensor(neg_items_list, dtype=torch.long)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 01 | Loss: 0.0978 | Time: 1.94s | Batch Users: 512\n",
            "Epoch 02 | Loss: 0.0868 | Time: 2.68s | Batch Users: 512\n",
            "Epoch 03 | Loss: 0.0840 | Time: 3.78s | Batch Users: 512\n",
            "Epoch 04 | Loss: 0.0788 | Time: 4.87s | Batch Users: 512\n",
            "Epoch 05 | Loss: 0.0738 | Time: 5.80s | Batch Users: 512\n",
            "Epoch 06 | Loss: 0.0776 | Time: 6.50s | Batch Users: 512\n",
            "Epoch 07 | Loss: 0.0781 | Time: 7.21s | Batch Users: 512\n",
            "Epoch 08 | Loss: 0.0731 | Time: 7.95s | Batch Users: 512\n",
            "Epoch 09 | Loss: 0.0723 | Time: 8.69s | Batch Users: 512\n",
            "Epoch 10 | Loss: 0.0719 | Time: 9.38s | Batch Users: 512\n",
            "Epoch 11 | Loss: 0.0717 | Time: 10.10s | Batch Users: 512\n",
            "Epoch 12 | Loss: 0.0743 | Time: 10.80s | Batch Users: 512\n",
            "Epoch 13 | Loss: 0.0720 | Time: 11.50s | Batch Users: 512\n",
            "Epoch 14 | Loss: 0.0725 | Time: 12.25s | Batch Users: 512\n",
            "Epoch 15 | Loss: 0.0719 | Time: 13.01s | Batch Users: 512\n",
            "Epoch 16 | Loss: 0.0739 | Time: 13.74s | Batch Users: 512\n",
            "Epoch 17 | Loss: 0.0721 | Time: 14.48s | Batch Users: 512\n",
            "Epoch 18 | Loss: 0.0670 | Time: 15.21s | Batch Users: 512\n",
            "Epoch 19 | Loss: 0.0692 | Time: 16.23s | Batch Users: 512\n",
            "Epoch 20 | Loss: 0.0703 | Time: 17.31s | Batch Users: 512\n",
            "Training finished.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Corrected Evaluation Function Definition ---\n",
        "# Note: The original evaluate function had placeholders (...) for model calls.\n",
        "# You need to implement how embeddings are generated during evaluation.\n",
        "# This often involves calling the model's forward pass appropriately for users/items.\n",
        "# The example below assumes the model's forward can handle empty edges for simple projection.\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(model, eval_data, train_data_edges, num_users, num_items, x_full, k=20, device=None):\n",
        "    model.eval()\n",
        "    if device is None:\n",
        "        device = x_full.device\n",
        "\n",
        "    print(\"Starting evaluation...\")\n",
        "    # Generate embeddings for all users and items using the *full* feature set (x_full)\n",
        "    # This might require running inference in batches if the graph is large,\n",
        "    # but for MovieLens-100k, we can often do it at once.\n",
        "    # The way you call the model here depends on its forward implementation.\n",
        "    # Assuming it can generate embeddings from features alone by passing empty edge info:\n",
        "    empty_edge_index = torch.empty(2, 0, dtype=torch.long, device=device)\n",
        "    empty_edge_weight = torch.empty(0, device=device)\n",
        "\n",
        "    # --- Generate User Embeddings ---\n",
        "    # Need to know how many nodes are in the user batch (num_users)\n",
        "    # We pass the relevant section of x_full\n",
        "    try:\n",
        "        user_emb = model(x_full[:num_users], # User features\n",
        "                         empty_edge_index,\n",
        "                         empty_edge_weight,\n",
        "                         batch_size=num_users) # Indicate the number of nodes being processed\n",
        "        print(f\"Generated user embeddings: {user_emb.shape}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating user embeddings: {e}\")\n",
        "        return None # Or handle error appropriately\n",
        "\n",
        "    # --- Generate Item Embeddings ---\n",
        "    # Need to know how many nodes are in the item batch (num_items)\n",
        "    # We pass the relevant section of x_full\n",
        "    try:\n",
        "        item_emb = model(x_full[num_users:], # Item features\n",
        "                         empty_edge_index,\n",
        "                         empty_edge_weight,\n",
        "                         batch_size=num_items) # Indicate the number of nodes being processed\n",
        "        print(f\"Generated item embeddings: {item_emb.shape}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating item embeddings: {e}\")\n",
        "        return None # Or handle error appropriately\n",
        "\n",
        "\n",
        "    # Compute scores for all user-item pairs\n",
        "    scores = user_emb @ item_emb.t() # [num_users, num_items]\n",
        "    print(f\"Computed scores matrix: {scores.shape}\")\n",
        "\n",
        "    # --- Masking Logic ---\n",
        "    test_edge_index = eval_data[\"user\", \"rates\", \"item\"].edge_index\n",
        "    test_mask = torch.zeros(num_users, num_items, dtype=torch.bool, device=device)\n",
        "    # Adjust item indices to be 0-based relative to the item set\n",
        "    test_mask[test_edge_index[0], test_edge_index[1] - num_users] = True\n",
        "    print(f\"Test mask created. Positive test interactions: {test_mask.sum().item()}\")\n",
        "\n",
        "\n",
        "    # --- Exclude training items ---\n",
        "    # Use the edge_index from the *original* training data split\n",
        "    train_mask = torch.zeros(num_users, num_items, dtype=torch.bool, device=device)\n",
        "    # Adjust item indices to be 0-based relative to the item set\n",
        "    train_mask[train_data_edges[0], train_data_edges[1] - num_users] = True\n",
        "    scores[train_mask] = -float(\"inf\") # Set score to negative infinity for training items\n",
        "    print(f\"Masked out {train_mask.sum().item()} training interactions.\")\n",
        "\n",
        "\n",
        "    # Get top-k predictions\n",
        "    try:\n",
        "        _, top_k_indices = scores.topk(k, dim=1) # [num_users, k]\n",
        "    except RuntimeError as e:\n",
        "        print(f\"Error during topk calculation: {e}\")\n",
        "        print(\"Check if k is larger than the number of items after masking.\")\n",
        "        return None\n",
        "\n",
        "\n",
        "    # Calculate recall@k\n",
        "    # Gather the test mask values corresponding to the top-k predictions\n",
        "    # Ensure test_mask is expanded or indices are handled correctly if needed\n",
        "    # For gather: top_k_indices should be LongTensor, test_mask BoolTensor\n",
        "    hits = test_mask.gather(1, top_k_indices).sum().item()\n",
        "    total_test_positives = test_mask.sum().item()\n",
        "\n",
        "    if total_test_positives == 0:\n",
        "        print(\"No positive edges in the test set!\")\n",
        "        recall = 0.0\n",
        "    else:\n",
        "        recall = hits / total_test_positives\n",
        "\n",
        "    print(f\"Recall@{k}: {recall:.4f} ({hits} hits / {total_test_positives} total test positives)\")\n",
        "    return recall\n",
        "\n",
        "# --- Call Evaluation ---\n",
        "# Pass the *training* edges to the evaluate function so it can mask them out\n",
        "evaluate(model, test_data, train_data[\"user\", \"rates\", \"item\"].edge_index, num_users, num_items, x_full, k=20, device=device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VYV4nj-LvKp7",
        "outputId": "502dbf19-040a-4e2b-b27c-b7dc2ba4d526"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting evaluation...\n",
            "Error generating user embeddings: get_all_embeddings() got an unexpected keyword argument 'device'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "swfKR5-WvS21"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}